做了一个实验, 观察分类任务中分类层的类权重范数与对应类别训练样本数之间的关系. 实验用了两个分类模型: 植物识别模型 (https://github.com/quarrying/quarrying-plant-id) 和昆虫识别模型 (https://github.com/quarrying/quarrying-insect-id), 这两个模型在训练时用的都是 plain softmax loss, 即没有用到特征归一化和权重归一化, 结果如图所示 (图例中的 spearmanr 指的是 spearman rank correlation). 由图可见, 两个模型有一致的结论: 类权重范数与训练样本数是正相关的. 不知道这个结论是不是普适的, 但似乎可以从直觉上来理解: 某类的训练样本数越多, 分类器对该类的分类就越有信心, 统计意义上该类的 logit 应具有较大的值, 而当特征固定且类权重方向固定的情况下, 只有类权重范数大, 该类的 logit 才具有较大的值. 从这个结论出发, 我们似乎可以理解为什么一些 softmax loss 的改进 loss 要对分类层权重进行归一化: **消除类别数目不均衡对分类层权重的影响**.

![](<20210929 类权重范数与样本数之间的关系/weight_norm-vs-num_examples.png>)
