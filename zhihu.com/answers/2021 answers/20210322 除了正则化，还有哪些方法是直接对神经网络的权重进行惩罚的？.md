#! https://www.zhihu.com/question/450687919/answer/1794329248

[comment]: <> (Answer URL: https://www.zhihu.com/question/450687919/answer/1794329248)
[comment]: <> "Question Title: 除了正则化，还有哪些方法是直接对神经网络的权重进行惩罚的？"
[comment]: <> (Author Name: https://www.zhihu.com/people/quarrying)

暂时想到：

1）weight normalization：对权重的范数进行了约束，人脸识别任务的网络中分类层常用到权重归一化。

2）weight quantization：相当于惩罚了权重的精度或取值范围等。

3）dropconnect：和dropout是一种对偶的操作，dropout作用于激活值上，dropconnect作用于网络权重上，将某些权重随机置零。

